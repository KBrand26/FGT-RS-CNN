{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from functools import partial\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from skimage.transform import rotate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import time\n",
    "from evaluate_models import plot_cm, process_labels, calc_precision_recall, calc_f1\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from train_models import train_derotated_standard, probe_dir\n",
    "from data_prep import norm_image, thresh_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = np.load('../../data/galaxy_X_train1.npy')\n",
    "X_val1 = np.load('../../data/galaxy_X_val1.npy')\n",
    "X_test1 = np.load('../../data/galaxy_X_test1.npy')\n",
    "y_train = np.load('../../data/galaxy_y_train.npy')\n",
    "y_val = np.load('../../data/galaxy_y_val.npy')\n",
    "y_test = np.load('../../data/galaxy_y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derotate_galaxies(galaxies):\n",
    "    '''\n",
    "    Standardise the rotation of the given galaxies.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    galaxies : ndarray\n",
    "        The radio galaxy samples that need to be derotated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        An array of derotated galaxies that corresponds to the given array of galaxies.\n",
    "    '''\n",
    "    derotated = []\n",
    "    identity = np.array([\n",
    "        [1, 0],\n",
    "        [0, 1]\n",
    "    ])\n",
    "    \n",
    "    for i in range(len(galaxies)):\n",
    "        # Preprocess images\n",
    "        img = norm_image(galaxies[i])\n",
    "        threshed, _ = thresh_image(img)\n",
    "\n",
    "        # Construct matrix with galaxy pixel coordinates\n",
    "        rows, cols = np.where(threshed > 0)\n",
    "        coords = np.array([cols, rows])\n",
    "        d,n = coords.shape\n",
    "        \n",
    "        # Centre the images at the origin\n",
    "        mean = np.mean(coords,axis=1)[:,np.newaxis]\n",
    "        coords = (coords - mean)\n",
    "\n",
    "        # Calculate the principal directions using the SVD\n",
    "        u, s, vh = np.linalg.svd(coords,full_matrices=False)\n",
    "        og_U = np.copy(u)\n",
    "        \n",
    "        # Determine if any rotation is necessary\n",
    "        if (np.abs(identity - u) < 1e-5).all():\n",
    "            # No rotation\n",
    "            derotated.append(img.copy())\n",
    "            continue\n",
    "            \n",
    "        # Calculate the angle of rotation\n",
    "        angle = np.arcsin(abs(u.T[0, 1]))*(180/np.pi)\n",
    "        r_angle = np.radians(angle)\n",
    "        tmp_cos = np.cos(r_angle)\n",
    "\n",
    "        # Undo reflections\n",
    "        if u[0, 0] != 0:\n",
    "            if u[1, 1] == 0:\n",
    "                print(f'VERY UNEXPECTED, this is not supposed to happen. Sample {i}')\n",
    "            if tmp_cos - u[0, 0] >= 1e-6:\n",
    "                if (tmp_cos - (-1*u[0, 0]) < 1e-6):\n",
    "                    print('Changing direction of first eigenvector')\n",
    "                    u[0, 0] = -1*u[0, 0]\n",
    "                    u[1, 0] = -1*u[1, 0]\n",
    "                else:\n",
    "                    print(f'UNEXPECTED: Cosine is not matching calculated angle for sample {i}')\n",
    "                    print(f'Cosine: {tmp_cos}')\n",
    "                    print(f'U: {u}')\n",
    "\n",
    "            if tmp_cos - u[1, 1] >= 1e-6:\n",
    "                if (tmp_cos - (-1*u[1, 1]) < 1e-6): \n",
    "                    print(f'Changing direction of second eigenvector in sample {i}')\n",
    "                    u[0, 1] = -1*u[0, 1]\n",
    "                    u[1, 1] = -1*u[1, 1]\n",
    "                else:\n",
    "                    print(f'UNEXPECTED: Cosine is not matching calculated angle for sample {i}')\n",
    "                    print(f'Cosine: {tmp_cos}')\n",
    "                    print(f'U: {u}')\n",
    "\n",
    "        # Identify and correct for special case where reflections cannot be detected\n",
    "        sgns = np.sign(u.T)\n",
    "        if u[0, 0] == 0:\n",
    "            if sgns[0, 1] + sgns[1, 0] != 0:\n",
    "                print(f'Cosines are zero and sines have same sign. Changing direction of second eigenvector for sample {i}')\n",
    "                u[0, 1] = -1*u[0, 1]\n",
    "                u[1, 1] = -1*u[1, 1]\n",
    "                sgns = np.sign(u.T)\n",
    "        if sgns[0, 1] + sgns[1, 0] != 0:\n",
    "            print(f'UNEXPECTED: Sine terms have the same sign for sample {i}')\n",
    "            print(f'U: {u}')\n",
    "\n",
    "        sgn = sgns[0, 1]\n",
    "\n",
    "        # Determine the direction of rotation\n",
    "        if sgn >= 0:\n",
    "            #Anti-clockwise rotation\n",
    "            r_img = rotate(img.copy(),angle)\n",
    "        else:\n",
    "            #Clockwise rotation\n",
    "            r_img = rotate(img.copy(),360-angle)\n",
    "            \n",
    "        # Double check whether matrix can be reconstructed\n",
    "        tmp = np.array([\n",
    "            [np.cos(r_angle), sgn*np.sin(r_angle)],\n",
    "            [(-1*sgn)*np.sin(r_angle), np.cos(r_angle)]\n",
    "        ])\n",
    "        if (np.abs(tmp - u.T) > 1e-6).any():\n",
    "            print('Problematic sample')\n",
    "            print(i)\n",
    "            print(tmp)\n",
    "            print(u)\n",
    "        derotated.append(r_img)\n",
    "    derotated = np.array(derotated)\n",
    "    return derotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file(file, imgs):\n",
    "    '''\n",
    "    Check if the file of derotated images already exists. If it does not, create it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : String\n",
    "        The location of the derotated images.\n",
    "    imgs: ndarray\n",
    "        The array of images that need to be derotated if the file does not exist\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        An array of derotated galaxies that corresponds to the given array of galaxies.\n",
    "    '''\n",
    "    if os.path.exists(file):\n",
    "        derotated = np.load(file)\n",
    "    else:\n",
    "        derotated = derotate_galaxies(imgs)\n",
    "        np.save(file, derotated)\n",
    "    return derotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the rotation of all of the training galaxies\n",
    "X_train2 = check_file('../../data/galaxy_X_train_derotated.npy', X_train1)\n",
    "X_val2 = check_file('../../data/galaxy_X_val_derotated.npy', X_val1)\n",
    "X_test2 = check_file('../../data/galaxy_X_test_derotated.npy', X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seeds to be able to reproduce network\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "def normalize_images(X):\n",
    "    return np.array(list(map(norm_image, X)))\n",
    "\n",
    "X_train = normalize_images(X_train2)\n",
    "X_val = normalize_images(X_val2)\n",
    "X_test = normalize_images(X_test2)\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_val = X_val[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 20\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "elapsed = 0\n",
    "times = []\n",
    "\n",
    "# Execute the training runs\n",
    "for run in range(1,runs+1):\n",
    "    start = time.time()\n",
    "    tmp_loss, tmp_acc = train_derotated_standard(X_train, y_train, X_val, y_val, X_test, y_test, run)\n",
    "    keras.backend.clear_session()\n",
    "    end = time.time()\n",
    "    elapsed += (end - start)\n",
    "    times.append(end-start)\n",
    "    total_loss += tmp_loss\n",
    "    total_acc += tmp_acc\n",
    "    \n",
    "probe_dir('../../time_logs/')\n",
    "np.save('../../time_logs/std_derotate_times.npy', times)\n",
    "avg_loss = total_loss/runs\n",
    "avg_acc = total_acc/runs\n",
    "avg_elapsed = elapsed/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the number of epochs it took to train the networks\n",
    "runs = 20\n",
    "epochs_log = []\n",
    "for run in range(1,runs+1):\n",
    "    ea = EventAccumulator(f'../../lr_logs/standard_derotated_run{run}/train')\n",
    "    ea.Reload()\n",
    "    ct_loss, epochs_loss, loss = zip(*ea.Tensors('epoch_loss'))\n",
    "    epochs_loss = np.asarray(epochs_loss)\n",
    "    epochs_log.append(epochs_loss[-1] + 1)\n",
    "\n",
    "epochs_log = np.array(epochs_log)\n",
    "avg_epochs = np.mean(epochs_log)\n",
    "min_idx = np.argmin(epochs_log) + 1\n",
    "min_epochs = epochs_log[min_idx - 1]\n",
    "max_idx = np.argmax(epochs_log) + 1\n",
    "max_epochs = epochs_log[max_idx - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the reported network performance\n",
    "tmp = np.array([avg_acc, avg_loss, avg_elapsed, avg_epochs, max_epochs, max_idx, min_epochs, min_idx])\n",
    "probe_dir('../../results/')\n",
    "np.save('../../results/standard_derotated_results.npy', tmp)\n",
    "tmp = np.load('../../results/standard_derotated_results.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average accuracy: {tmp[0]}\")\n",
    "print(f\"Average loss: {tmp[1]}\")\n",
    "print(f\"Average time taken: {tmp[2]}\")\n",
    "print(f\"Average epochs taken: {tmp[3]}\")\n",
    "print(f\"Maximum number of epochs taken was {tmp[4]} at run {tmp[5]}\")\n",
    "print(f\"Minimum number of epochs taken was {tmp[6]} at run {tmp[7]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional performance evaluation\n",
    "bent_precs, bent_recalls, bent_f1s = [], [], []\n",
    "comp_precs, comp_recalls, comp_f1s = [], [], []\n",
    "fri_precs, fri_recalls, fri_f1s = [], [], []\n",
    "frii_precs, frii_recalls, frii_f1s = [], [], []\n",
    "macro_f1s = []\n",
    "average_cm = np.zeros((4, 4))\n",
    "runs = 20\n",
    "for run in range(1,runs+1):\n",
    "    best_model = keras.models.load_model(f\"../../models/derotated_standard_model{run}.h5\")\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    average_cm += cm\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_precs.append(bent_prec)\n",
    "    bent_recalls.append(bent_recall)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_precs.append(comp_prec)\n",
    "    comp_recalls.append(comp_recall)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_precs.append(fri_prec)\n",
    "    fri_recalls.append(fri_recall)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_precs.append(frii_prec)\n",
    "    frii_recalls.append(frii_recall)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "\n",
    "average_cm = average_cm/runs\n",
    "print(f'Average bent precision: {np.mean(bent_precs)}')\n",
    "print(f'Average bent recall: {np.mean(bent_recalls)}')\n",
    "print(f'Average bent F1: {np.mean(bent_f1s)}')\n",
    "print(f'Average comp precision: {np.mean(comp_precs)}')\n",
    "print(f'Average comp recall: {np.mean(comp_recalls)}')\n",
    "print(f'Average comp F1: {np.mean(comp_f1s)}')\n",
    "print(f'Average FRI precision: {np.mean(fri_precs)}')\n",
    "print(f'Average FRI recall: {np.mean(fri_recalls)}')\n",
    "print(f'Average FRI F1: {np.mean(fri_f1s)}')\n",
    "print(f'Average FRII precision: {np.mean(frii_precs)}')\n",
    "print(f'Average FRII recall: {np.mean(frii_recalls)}')\n",
    "print(f'Average FRII F1: {np.mean(frii_f1s)}')\n",
    "print(f'Average Macro F1: {np.mean(macro_f1s)}')\n",
    "plot_cm(average_cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
