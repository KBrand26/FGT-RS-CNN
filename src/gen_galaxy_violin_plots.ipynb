{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from evaluate_models import plot_cm, process_labels, calc_precision_recall, calc_f1\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from custom_plots import gen_violin_plot, tensor_to_val\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../data/galaxy_X.npy')\n",
    "y = np.load('../data/galaxy_y.npy')\n",
    "y_aux = np.load('../data/galaxy_y_aux.npy')\n",
    "y_man_aux = np.load('../data/galaxy_y_manual_aux.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seeds to be able to reproduce results\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp_train, X_test1, y_aux_tmp_train, y_aux_test1, y_man_aux_tmp_train, y_man_aux_test1, y_tmp_train, y_test = train_test_split(X, y_aux, y_man_aux, y, test_size=0.1, train_size=0.9, random_state=42, shuffle=True, stratify=y)\n",
    "X_train1, X_val1, y_aux_train1, y_aux_val1, y_man_aux_train1, y_man_aux_val1, y_train, y_val = train_test_split(X_tmp_train, y_aux_tmp_train, y_man_aux_tmp_train, y_tmp_train, test_size=0.11, train_size=0.89, random_state=42, shuffle=True, stratify=y_tmp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(X):\n",
    "    return np.array(list(map(normalize_image, X)))\n",
    "    \n",
    "def normalize_image(img):\n",
    "    bot = np.min(img)\n",
    "    top = np.max(img)\n",
    "    norm = (img - bot)/(top - bot)\n",
    "    return norm\n",
    "\n",
    "X_train = normalize_images(X_train1)\n",
    "X_val = normalize_images(X_val1)\n",
    "X_test = normalize_images(X_test1)\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_val = X_val[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_targets(y):\n",
    "    bot = np.min(y, axis=0)\n",
    "    top = np.max(y, axis=0)\n",
    "    norm = (y - bot)/(top - bot)\n",
    "    return norm\n",
    "\n",
    "y_aux_train = normalize_targets(y_aux_train1)\n",
    "y_aux_val = normalize_targets(y_aux_val1)\n",
    "y_aux_test = normalize_targets(y_aux_test1)\n",
    "y_man_aux_train = normalize_targets(y_man_aux_train1)\n",
    "y_man_aux_val = normalize_targets(y_man_aux_val1)\n",
    "y_man_aux_test = normalize_targets(y_man_aux_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_class_pred(preds):\n",
    "    return preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_predictions(pred):\n",
    "    length = len(pred[0])\n",
    "    new_preds = []\n",
    "    for j in range(length):\n",
    "        feats = []\n",
    "        for i in range(4):\n",
    "            feats.append(pred[i][j, 0])\n",
    "        new_preds.append(feats)\n",
    "    return np.array(new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bent = y_aux_test[:, 0]\n",
    "y_test_fr = y_aux_test[:, 1]\n",
    "y_test_cores = y_aux_test[:, 2]\n",
    "y_test_size = y_aux_test[:, 3]\n",
    "test_labels = {\n",
    "    'main_out': y_test,\n",
    "    'bent_out': y_test_bent,\n",
    "    'fr_out': y_test_fr,\n",
    "    'cores_out': y_test_cores,\n",
    "    'size_out': y_test_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_man_test_bent = y_man_aux_test[:, 0]\n",
    "y_man_test_fr = y_man_aux_test[:, 1]\n",
    "y_man_test_cores = y_man_aux_test[:, 2]\n",
    "y_man_test_size = y_man_aux_test[:, 3]\n",
    "man_test_labels = {\n",
    "    'main_out': y_test,\n",
    "    'bent_out': y_man_test_bent,\n",
    "    'fr_out': y_man_test_fr,\n",
    "    'cores_out': y_man_test_cores,\n",
    "    'size_out': y_man_test_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bent_f1s = []\n",
    "comp_f1s = []\n",
    "fri_f1s = []\n",
    "frii_f1s = []\n",
    "macro_f1s = []\n",
    "model = []\n",
    "run_log = []\n",
    "epochs = []\n",
    "accuracy = []\n",
    "full_loss = []\n",
    "main_loss = []\n",
    "overfit = []\n",
    "overfit_scores = []\n",
    "true_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine even merged performance\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):        \n",
    "    loc = f'../models/merged_0.5_0.5_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Even\\nMCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/merged_0.5_0.5_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    # Use validation data to calculate overfitting\n",
    "    name = f'../lr_logs/merged_0.5_0.5_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Automated')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/merged_0.5_0.5_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/merged_0.5_0.5_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine aux merged performance\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    loc = f'../models/merged_0.25_0.75_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Aux\\nMCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/merged_0.25_0.75_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/merged_0.25_0.75_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Automated')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/merged_0.25_0.75_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/merged_0.25_0.75_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f41abf4d1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f41abf4d940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f41abdc1ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f41abdfb3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# Determine main merged performance\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    loc = f'../models/merged_0.75_0.25_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Main\\nMCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/merged_0.75_0.25_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/merged_0.75_0.25_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Automated')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/merged_0.75_0.25_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/merged_0.75_0.25_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine even multihead performance\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    loc = f'../models/multihead_0.5_0.5_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Even\\nMhCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/multihead_0.5_0.5_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/multihead_0.5_0.5_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Automated')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/multihead_0.5_0.5_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/multihead_0.5_0.5_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine aux multihead performance\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    loc = f'../models/multihead_0.25_0.75_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Aux\\nMhCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/multihead_0.25_0.75_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/multihead_0.25_0.75_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Automated')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/multihead_0.25_0.75_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/multihead_0.25_0.75_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine main multihead performance\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    loc = f'../models/multihead_0.75_0.25_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Main\\nMhCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/multihead_0.75_0.25_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/multihead_0.75_0.25_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Automated')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/multihead_0.75_0.25_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/multihead_0.75_0.25_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine standard performance\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    best_model = keras.models.load_model(f\"../models/standard_model{run}.h5\")\n",
    "    tmp_loss, tmp_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('SCNN')\n",
    "    accuracy.append(tmp_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_loss)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/standard_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/standard_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Automated')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/standard_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/standard_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine wide performance\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    aux_model = keras.models.load_model(f'../models/aux_model{run}.h5')\n",
    "    X_test_pred = aux_model.predict(X_test)\n",
    "    X_test_aux = reshape_predictions(X_test_pred) \n",
    "    best_model = keras.models.load_model(f\"../models/wide_model{run}.h5\")\n",
    "    tmp_loss, tmp_acc = best_model.evaluate((X_test_aux, X_test), y_test, verbose=0)\n",
    "    test_pred = best_model.predict((X_test_aux, X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('WCNN')\n",
    "    accuracy.append(tmp_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_loss)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/wide_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/wide_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Automated')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/wide_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/wide_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine even merged performance with additional manual labels\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):        \n",
    "    loc = f'../models/man_merged_0.5_0.5_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, man_test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Even\\nMCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_merged_0.5_0.5_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/man_merged_0.5_0.5_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Manual')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_merged_0.5_0.5_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/man_merged_0.5_0.5_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine aux merged performance with additional manual labels\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    loc = f'../models/man_merged_0.25_0.75_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, man_test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Aux\\nMCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_merged_0.25_0.75_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/man_merged_0.25_0.75_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Manual')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_merged_0.25_0.75_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/man_merged_0.25_0.75_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine main merged performance with additional manual labels\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    loc = f'../models/man_merged_0.75_0.25_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, man_test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Main\\nMCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_merged_0.75_0.25_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/man_merged_0.75_0.25_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Manual')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_merged_0.75_0.25_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/man_merged_0.75_0.25_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine even multihead performance with additional manual labels\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    loc = f'../models/man_multihead_0.5_0.5_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, man_test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Even\\nMhCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_multihead_0.5_0.5_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/man_multihead_0.5_0.5_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Manual')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_multihead_0.5_0.5_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/man_multihead_0.5_0.5_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine auxiliary multihead performance with additional manual labels\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    loc = f'../models/man_multihead_0.25_0.75_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, man_test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Aux\\nMhCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_multihead_0.25_0.75_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/man_multihead_0.25_0.75_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Manual')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_multihead_0.25_0.75_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/man_multihead_0.25_0.75_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine main multihead performance with additional manual labels\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    loc = f'../models/man_multihead_0.75_0.25_model{run}.h5'\n",
    "    best_model = keras.models.load_model(loc)\n",
    "    tmp_loss, tmp_lbl_entropy, tmp_bent_entropy, tmp_fr_mse, tmp_cores_mse, tmp_size_mse, tmp_lbl_acc, tmp_bent_acc, tmp_fr_mae, tmp_cores_mae, tmp_size_mae = best_model.evaluate(X_test, man_test_labels, verbose=0)\n",
    "    test_pred = extract_class_pred(best_model.predict(X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Main\\nMhCNN')\n",
    "    accuracy.append(tmp_lbl_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_lbl_entropy)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_multihead_0.75_0.25_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/man_multihead_0.75_0.25_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Manual')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_multihead_0.75_0.25_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/man_multihead_0.75_0.25_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine standard performance\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    best_model = keras.models.load_model(f\"../models/standard_model{run}.h5\")\n",
    "    tmp_loss, tmp_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('SCNN')\n",
    "    accuracy.append(tmp_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_loss)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/standard_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/standard_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Manual')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/standard_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/standard_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine wide performance with additional manual labels\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    aux_model = keras.models.load_model(f'../models/man_aux_model{run}.h5')\n",
    "    X_test_pred = aux_model.predict(X_test)\n",
    "    X_test_aux = reshape_predictions(X_test_pred) \n",
    "    best_model = keras.models.load_model(f\"../models/man_wide_model{run}.h5\")\n",
    "    tmp_loss, tmp_acc = best_model.evaluate((X_test_aux, X_test), y_test, verbose=0)\n",
    "    test_pred = best_model.predict((X_test_aux, X_test))\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('WCNN')\n",
    "    accuracy.append(tmp_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_loss)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_wide_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/man_wide_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    true_labels.append('Manual')\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "# Fit scaler to normalize range of loss values\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "# Second loop through data to normalize loss values and calculate overfitting score\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/man_wide_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/man_wide_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Model': model,\n",
    "    'Macro F1': macro_f1s,\n",
    "    'Bent F1': bent_f1s,\n",
    "    'Comp F1': comp_f1s,\n",
    "    'FRI F1': fri_f1s,\n",
    "    'FRII F1': frii_f1s,\n",
    "    'Accuracy': accuracy,\n",
    "    'Aggregated Loss': full_loss,\n",
    "    'Classification Loss': main_loss,\n",
    "    'Epochs': epochs,\n",
    "    'Overfitting ratio': overfit,\n",
    "    'Overfitting score': overfit_scores,\n",
    "    'Feature Vector Type': true_labels,\n",
    "    'Run': run_log\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"../plots/Galaxy/\"):\n",
    "    if os.getcwd().split(\"/\")[-1] == \"src\":\n",
    "        os.mkdir(\"../plots/Galaxy\")\n",
    "    else:\n",
    "        print(\"This function should only be called from the src directory\")\n",
    "gen_violin_plot(df, 'Model', 'Macro F1', 'Feature Vector Type', 'Galaxy/DualMacroF1s.eps')\n",
    "gen_violin_plot(df, 'Model', 'Bent F1', 'Feature Vector Type', 'Galaxy/DualBentF1s.eps')\n",
    "gen_violin_plot(df, 'Model', 'Comp F1', 'Feature Vector Type', 'Galaxy/DualCompF1s.eps')\n",
    "gen_violin_plot(df, 'Model', 'FRI F1', 'Feature Vector Type', 'Galaxy/DualFRIF1s.eps')\n",
    "gen_violin_plot(df, 'Model', 'FRII F1', 'Feature Vector Type', 'Galaxy/DualFRIIF1s.eps')\n",
    "gen_violin_plot(df, 'Model', 'Accuracy', 'Feature Vector Type', 'Galaxy/DualAccuracies.eps')\n",
    "gen_violin_plot(df, 'Model', 'Aggregated Loss', 'Feature Vector Type', 'Galaxy/DualFullLosses.eps')\n",
    "gen_violin_plot(df, 'Model', 'Classification Loss', 'Feature Vector Type', 'Galaxy/DualClassLoss.eps')\n",
    "gen_violin_plot(df, 'Model', 'Epochs', 'Feature Vector Type', 'Galaxy/DualEpochsFull.eps')\n",
    "gen_violin_plot(df, 'Model', 'Epochs', 'Feature Vector Type', 'Galaxy/DualEpochs.eps', only_data=True, limit=True, limit_range=[10, 28])\n",
    "gen_violin_plot(df, 'Model', 'Overfitting ratio', 'Feature Vector Type', 'Galaxy/DualOverfitFull.eps')\n",
    "gen_violin_plot(df, 'Model', 'Overfitting ratio', 'Feature Vector Type', 'Galaxy/DualOverfit.eps', only_data=True)\n",
    "gen_violin_plot(df, 'Model', 'Overfitting score', 'Feature Vector Type', 'Galaxy/DualOverfitScoreFull.eps')\n",
    "gen_violin_plot(df, 'Model', 'Overfitting score', 'Feature Vector Type', 'Galaxy/DualOverfitScore.eps', only_data=True, limit=True, limit_range=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['Feature Vector Type'] == 'Automated']\n",
    "gen_violin_plot(df2, 'Model', 'Macro F1', 'Feature Vector Type', 'Galaxy/FullMacroF1s.eps', split=False)\n",
    "gen_violin_plot(df2, 'Model', 'Macro F1', 'Feature Vector Type', 'Galaxy/MacroF1s.eps', split=False, only_data=True)\n",
    "gen_violin_plot(df2, 'Model', 'Bent F1', 'Feature Vector Type', 'Galaxy/BentF1s.eps', split=False)\n",
    "gen_violin_plot(df2, 'Model', 'Comp F1', 'Feature Vector Type', 'Galaxy/CompF1s.eps', split=False)\n",
    "gen_violin_plot(df2, 'Model', 'FRI F1', 'Feature Vector Type', 'Galaxy/FRIF1s.eps', split=False)\n",
    "gen_violin_plot(df2, 'Model', 'FRII F1', 'Feature Vector Type', 'Galaxy/FRIIF1s.eps', split=False)\n",
    "gen_violin_plot(df2, 'Model', 'Accuracy', 'Feature Vector Type', 'Galaxy/FullAccuracies.eps', split=False)\n",
    "gen_violin_plot(df2, 'Model', 'Accuracy', 'Feature Vector Type', 'Galaxy/Accuracies.eps', split=False, only_data=True)\n",
    "gen_violin_plot(df2, 'Model', 'Aggregated Loss', 'Feature Vector Type', 'Galaxy/FullLosses.eps', split=False)\n",
    "gen_violin_plot(df2, 'Model', 'Classification Loss', 'Feature Vector Type', 'Galaxy/FullClassLoss.eps', split=False)\n",
    "gen_violin_plot(df2, 'Model', 'Classification Loss', 'Feature Vector Type', 'Galaxy/ClassLoss.eps', split=False, only_data=True)\n",
    "gen_violin_plot(df2, 'Model', 'Epochs', 'Feature Vector Type', 'Galaxy/FullEpochs.eps', split=False)\n",
    "gen_violin_plot(df2, 'Model', 'Epochs', 'Feature Vector Type', 'Galaxy/Epochs.eps', split=False, only_data=True)\n",
    "gen_violin_plot(df2, 'Model', 'Overfitting ratio', 'Feature Vector Type', 'Galaxy/FullOverfit.eps', split=False)\n",
    "gen_violin_plot(df2, 'Model', 'Overfitting ratio', 'Feature Vector Type', 'Galaxy/Overfit.eps', only_data=True, split=False)\n",
    "gen_violin_plot(df2, 'Model', 'Overfitting score', 'Feature Vector Type', 'Galaxy/FullOverfitScore.eps', split=False)\n",
    "gen_violin_plot(df2, 'Model', 'Overfitting score', 'Feature Vector Type', 'Galaxy/OverfitScore.eps', split=False, only_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes for future use\n",
    "if not os.path.exists('../Dataframes/'):\n",
    "        os.makedirs('../Dataframes/')\n",
    "df.to_csv('../Dataframes/combined.csv', index=False)\n",
    "df2.to_csv('../Dataframes/automatic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derotated comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = np.load('../data/galaxy_X_test1.npy')\n",
    "y_test = np.load('../data/galaxy_y_test.npy')\n",
    "X_der_test1 = np.load('../data/galaxy_X_test_derotated.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seeds to be able to reproduce results\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(X):\n",
    "    return np.array(list(map(normalize_image, X)))\n",
    "    \n",
    "def normalize_image(img):\n",
    "    bot = np.min(img)\n",
    "    top = np.max(img)\n",
    "    norm = (img - bot)/(top - bot)\n",
    "    return norm\n",
    "\n",
    "X_test = normalize_images(X_test1)\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "X_der_test = normalize_images(X_der_test1)\n",
    "X_der_test = X_der_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bent_f1s = []\n",
    "comp_f1s = []\n",
    "fri_f1s = []\n",
    "frii_f1s = []\n",
    "macro_f1s = []\n",
    "model = []\n",
    "run_log = []\n",
    "epochs = []\n",
    "accuracy = []\n",
    "full_loss = []\n",
    "main_loss = []\n",
    "overfit = []\n",
    "overfit_scores = []\n",
    "train_times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_times = np.load('../time_logs/standard_times.npy')\n",
    "std_aug_times = np.load('../time_logs/standard_aug_times.npy')\n",
    "std_derotate_times = np.load('../time_logs/std_derotate_times.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine standard performance\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    train_times.append(std_times[run-1])\n",
    "    \n",
    "    best_model = keras.models.load_model(f\"../models/standard_model{run}.h5\")\n",
    "    tmp_loss, tmp_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Standard')\n",
    "    accuracy.append(tmp_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_loss)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/standard_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/standard_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/standard_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/standard_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine standard performance with standardized rotation\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    train_times.append(std_derotate_times[run-1])\n",
    "    \n",
    "    best_model = keras.models.load_model(f\"../models/derotated_standard_model{run}.h5\")\n",
    "    tmp_loss, tmp_acc = best_model.evaluate(X_der_test, y_test, verbose=0)\n",
    "    test_pred = best_model.predict(X_der_test)\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Derotated')\n",
    "    accuracy.append(tmp_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_loss)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/standard_derotated_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/standard_derotated_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/standard_derotated_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/standard_derotated_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8ffc3be3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8ffc3be9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8ffcc22310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8ffcd09430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# Determine standard augmented performance\n",
    "runs = 20\n",
    "all_losses = []\n",
    "scaler = MinMaxScaler()\n",
    "for run in range(1,runs+1):\n",
    "    train_times.append(std_aug_times[run-1])\n",
    "    \n",
    "    best_model = keras.models.load_model(f\"../models/aug_standard_model{run}.h5\")\n",
    "    tmp_loss, tmp_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    new_test_true, new_test_pred = process_labels(y_test, test_pred)\n",
    "    cm = confusion_matrix(new_test_true, new_test_pred)\n",
    "    bent_prec, bent_recall = calc_precision_recall(cm, 0)\n",
    "    bent_f1s.append(calc_f1(bent_prec, bent_recall))\n",
    "    comp_prec, comp_recall = calc_precision_recall(cm, 1)\n",
    "    comp_f1s.append(calc_f1(comp_prec, comp_recall))\n",
    "    fri_prec, fri_recall = calc_precision_recall(cm, 2)\n",
    "    fri_f1s.append(calc_f1(fri_prec, fri_recall))\n",
    "    frii_prec, frii_recall = calc_precision_recall(cm, 3)\n",
    "    frii_f1s.append(calc_f1(frii_prec, frii_recall))\n",
    "    macro_f1s.append((bent_f1s[-1] + comp_f1s[-1] + fri_f1s[-1] + frii_f1s[-1])/4)\n",
    "    run_log.append(run)\n",
    "    model.append('Augmented')\n",
    "    accuracy.append(tmp_acc)\n",
    "    full_loss.append(tmp_loss)\n",
    "    main_loss.append(tmp_loss)\n",
    "    \n",
    "    # Get loss, accuracy and epoch information \n",
    "    name = f'../lr_logs/standard_aug_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    epochs.append(epoch_loss[-1] + 1)\n",
    "    \n",
    "    name = f'../lr_logs/standard_aug_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    overfit.append(val_loss[-1]/train_loss[-1])\n",
    "    \n",
    "    all_losses = all_losses + train_loss + val_loss\n",
    "\n",
    "all_losses = np.array(all_losses).reshape(-1, 1)\n",
    "scaler.fit(all_losses)\n",
    "\n",
    "for run in range(1,runs+1):    \n",
    "    # Get loss, accuracy and epoch information    \n",
    "    name = f'../lr_logs/standard_aug_run{run}/train'\n",
    "    loss_name = 'epoch_loss'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    ct, epoch_loss, train_loss = zip(*ea.Tensors(loss_name))\n",
    "    epoch_loss = list(epoch_loss)\n",
    "    train_loss = list(train_loss)\n",
    "    train_loss= list(map(tensor_to_val, train_loss))\n",
    "    train_loss = np.array(train_loss).reshape(-1, 1)\n",
    "    train_loss = scaler.transform(train_loss)\n",
    "    \n",
    "    name = f'../lr_logs/standard_aug_run{run}/validation'\n",
    "    ea = EventAccumulator(name)\n",
    "    ea.Reload()\n",
    "    _, _, val_loss = zip(*ea.Tensors(loss_name))\n",
    "    val_loss = list(val_loss)\n",
    "    val_loss= list(map(tensor_to_val, val_loss))\n",
    "    val_loss = np.array(val_loss).reshape(-1, 1)\n",
    "    val_loss = scaler.transform(val_loss)\n",
    "    \n",
    "    overfit_scores.append(val_loss[-1, 0] - train_loss[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Model': model,\n",
    "    'Macro F1': macro_f1s,\n",
    "    'Bent F1': bent_f1s,\n",
    "    'Comp F1': comp_f1s,\n",
    "    'FRI F1': fri_f1s,\n",
    "    'FRII F1': frii_f1s,\n",
    "    'Accuracy': accuracy,\n",
    "    'Classification Loss': main_loss,\n",
    "    'Epochs': epochs,\n",
    "    'Overfitting ratio': overfit,\n",
    "    'Overfitting scores': overfit_scores,\n",
    "    'Training times': train_times,\n",
    "    'Run': run_log\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "if not os.path.exists(\"../plots/Galaxy/\"):\n",
    "    if os.getcwd().split(\"/\")[-1] == \"src\":\n",
    "        os.mkdir(\"../plots/Galaxy\")\n",
    "    else:\n",
    "        print(\"This function should only be called from the src directory\")\n",
    "\n",
    "gen_violin_plot(df, 'Model', 'Macro F1', 'True feature vectors', 'Galaxy/RotationFullMacroF1s.eps', split=False)\n",
    "gen_violin_plot(df, 'Model', 'Macro F1', 'True feature vectors', 'Galaxy/RotationMacroF1s.eps', split=False, only_data=True)\n",
    "gen_violin_plot(df, 'Model', 'Bent F1', 'True feature vectors', 'Galaxy/RotationBentF1s.eps', split=False)\n",
    "gen_violin_plot(df, 'Model', 'Comp F1', 'True feature vectors', 'Galaxy/RotationCompF1s.eps', split=False)\n",
    "gen_violin_plot(df, 'Model', 'FRI F1', 'True feature vectors', 'Galaxy/RotationFRIF1s.eps', split=False)\n",
    "gen_violin_plot(df, 'Model', 'FRII F1', 'True feature vectors', 'Galaxy/RotationFRIIF1s.eps', split=False)\n",
    "gen_violin_plot(df, 'Model', 'Accuracy', 'True feature vectors', 'Galaxy/RotationFullAccuracies.eps', split=False)\n",
    "gen_violin_plot(df, 'Model', 'Accuracy', 'True feature vectors', 'Galaxy/RotationAccuracies.eps', split=False, only_data=True)\n",
    "gen_violin_plot(df, 'Model', 'Classification Loss', 'True feature vectors', 'Galaxy/RotationFullClassLoss.eps', split=False)\n",
    "gen_violin_plot(df, 'Model', 'Classification Loss', 'True feature vectors', 'Galaxy/RotationClassLoss.eps', split=False, only_data=True)\n",
    "gen_violin_plot(df, 'Model', 'Epochs', 'True feature vectors', 'Galaxy/RotationFullEpochs.eps', split=False)\n",
    "gen_violin_plot(df, 'Model', 'Epochs', 'True feature vectors', 'Galaxy/RotationEpochs.eps', split=False, only_data=True)\n",
    "gen_violin_plot(df, 'Model', 'Overfitting ratio', 'True feature vectors', 'Galaxy/RotationOverfitFull.eps', split=False)\n",
    "gen_violin_plot(df, 'Model', 'Overfitting ratio', 'True feature vectors', 'Galaxy/RotationOverfit.eps', split=False, only_data=True)\n",
    "gen_violin_plot(df, 'Model', 'Training times', 'True feature vectors', 'Galaxy/RotationFullTimes.eps', split=False)\n",
    "gen_violin_plot(df, 'Model', 'Training times', 'True feature vectors', 'Galaxy/RotationTimes.eps', split=False, only_data=True)\n",
    "gen_violin_plot(df, 'Model', 'Overfitting scores', 'True feature vectors', 'Galaxy/RotationFullOverfitScores.eps', split=False)\n",
    "gen_violin_plot(df, 'Model', 'Overfitting scores', 'True feature vectors', 'Galaxy/RotationOverfitScores.eps', split=False, only_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb3ce73e420acd05a8bea1bac9c382afc4d9849422ab23e32cd49090816aa4b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
